{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlyssaAmod/UNN_BraTS23/blob/main/3d_segmentation/unet_segmentation_3d_ignite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6VjHuk9N-Z4"
      },
      "source": [
        "Copyright (c) MONAI Consortium  \n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");  \n",
        "you may not use this file except in compliance with the License.  \n",
        "You may obtain a copy of the License at  \n",
        "&nbsp;&nbsp;&nbsp;&nbsp;http://www.apache.org/licenses/LICENSE-2.0  \n",
        "Unless required by applicable law or agreed to in writing, software  \n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,  \n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  \n",
        "See the License for the specific language governing permissions and  \n",
        "limitations under the License.\n",
        "\n",
        "# 3D Segmentation with UNet\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Project-MONAI/tutorials/blob/main/3d_segmentation/unet_segmentation_3d_ignite.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDHMC3nzN-Z9"
      },
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "ZmNwNMiQN-Z-"
      },
      "outputs": [],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[ignite, nibabel, tensorboard, mlflow]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6a6ZU5tN-aA"
      },
      "source": [
        "## Setup imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "NMYBQfXgN-aA",
        "outputId": "7ee591a6-00c2-492b-d030-8ad41882f897"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MONAI version: 0.9.1\n",
            "Numpy version: 1.22.4\n",
            "Pytorch version: 1.13.0a0+340c412\n",
            "MONAI flags: HAS_EXT = True, USE_COMPILED = False, USE_META_DICT = False\n",
            "MONAI rev id: 356d2d2f41b473f588899d705bbc682308cee52c\n",
            "MONAI __file__: /opt/monai/monai/__init__.py\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: 0.4.9\n",
            "Nibabel version: 4.0.1\n",
            "scikit-image version: 0.19.3\n",
            "Pillow version: 9.0.1\n",
            "Tensorboard version: 2.9.1\n",
            "gdown version: 4.5.1\n",
            "TorchVision version: 0.13.0a0\n",
            "tqdm version: 4.64.0\n",
            "lmdb version: 1.3.0\n",
            "psutil version: 5.9.1\n",
            "pandas version: 1.3.5\n",
            "einops version: 0.4.1\n",
            "transformers version: 4.20.1\n",
            "mlflow version: 1.27.0\n",
            "pynrrd version: 0.4.3\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import sys\n",
        "import tempfile\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from monai.config import print_config\n",
        "from monai.data import ArrayDataset, create_test_image_3d, decollate_batch, DataLoader\n",
        "from monai.handlers import (\n",
        "    MeanDice,\n",
        "    MLFlowHandler,\n",
        "    StatsHandler,\n",
        "    TensorBoardImageHandler,\n",
        "    TensorBoardStatsHandler,\n",
        ")\n",
        "from monai.losses import DiceLoss\n",
        "from monai.networks.nets import UNet\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    EnsureChannelFirst,\n",
        "    AsDiscrete,\n",
        "    Compose,\n",
        "    LoadImage,\n",
        "    RandSpatialCrop,\n",
        "    Resize,\n",
        "    ScaleIntensity,\n",
        ")\n",
        "from monai.utils import first\n",
        "\n",
        "import ignite\n",
        "import torch\n",
        "\n",
        "print_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okXEgrA3N-aB"
      },
      "source": [
        "## Setup data directory\n",
        "\n",
        "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.  \n",
        "This allows you to save results and reuse downloads.  \n",
        "If not specified a temporary directory will be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "ejl3j6L7N-aC",
        "outputId": "a2fcfcab-3a18-44ef-85b9-bec7c5c8d9d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace/data/medical\n"
          ]
        }
      ],
      "source": [
        "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
        "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
        "print(root_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxjqrLplN-aC"
      },
      "source": [
        "## Setup logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQSkjFkEN-aC"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnX_I2FXN-aD"
      },
      "source": [
        "## Setup demo data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOwwzAQ8N-aD"
      },
      "outputs": [],
      "source": [
        "for i in range(40):\n",
        "    im, seg = create_test_image_3d(128, 128, 128, num_seg_classes=1)\n",
        "\n",
        "    n = nib.Nifti1Image(im, np.eye(4))\n",
        "    nib.save(n, os.path.join(root_dir, f\"im{i}.nii.gz\"))\n",
        "\n",
        "    n = nib.Nifti1Image(seg, np.eye(4))\n",
        "    nib.save(n, os.path.join(root_dir, f\"seg{i}.nii.gz\"))\n",
        "\n",
        "images = sorted(glob.glob(os.path.join(root_dir, \"im*.nii.gz\")))\n",
        "segs = sorted(glob.glob(os.path.join(root_dir, \"seg*.nii.gz\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLlKfBogN-aD"
      },
      "source": [
        "## Setup transforms, dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "C42pFz7mN-aD",
        "outputId": "04591281-e38f-4f08-8469-6fbb40924959"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 1, 96, 96, 96]) torch.Size([10, 1, 96, 96, 96])\n"
          ]
        }
      ],
      "source": [
        "# Define transforms for image and segmentation\n",
        "imtrans = Compose(\n",
        "    [\n",
        "        LoadImage(image_only=True),\n",
        "        ScaleIntensity(),\n",
        "        EnsureChannelFirst(),\n",
        "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
        "    ]\n",
        ")\n",
        "segtrans = Compose(\n",
        "    [\n",
        "        LoadImage(image_only=True),\n",
        "        EnsureChannelFirst(),\n",
        "        RandSpatialCrop((96, 96, 96), random_size=False),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define nifti dataset, dataloader\n",
        "ds = ArrayDataset(images, imtrans, segs, segtrans)\n",
        "loader = DataLoader(ds, batch_size=10, num_workers=2, pin_memory=torch.cuda.is_available())\n",
        "im, seg = first(loader)\n",
        "print(im.shape, seg.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mX8Hho6N-aE"
      },
      "source": [
        "## Create Model, Loss, Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6qVQ6TmN-aE"
      },
      "outputs": [],
      "source": [
        "# Create UNet, DiceLoss and Adam optimizer\n",
        "device = torch.device(\"cuda:0\")\n",
        "net = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=1,\n",
        "    channels=(16, 32, 64, 128, 256),\n",
        "    strides=(2, 2, 2, 2),\n",
        "    num_res_units=2,\n",
        ").to(device)\n",
        "\n",
        "loss = DiceLoss(sigmoid=True)\n",
        "lr = 1e-3\n",
        "opt = torch.optim.Adam(net.parameters(), lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XswLbe6FN-aE"
      },
      "source": [
        "## Create supervised_trainer using ignite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJRQRRV9N-aE"
      },
      "outputs": [],
      "source": [
        "# Create trainer\n",
        "trainer = ignite.engine.create_supervised_trainer(net, opt, loss, device, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4N9GQ1XN-aE"
      },
      "source": [
        "## Setup event handlers for checkpointing and logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "M1GvxZ0jN-aF"
      },
      "outputs": [],
      "source": [
        "# optional section for checkpoint and tensorboard logging\n",
        "# adding checkpoint handler to save models (network\n",
        "# params and optimizer stats) during training\n",
        "log_dir = os.path.join(root_dir, \"logs\")\n",
        "checkpoint_handler = ignite.handlers.ModelCheckpoint(log_dir, \"net\", n_saved=10, require_empty=False)\n",
        "trainer.add_event_handler(\n",
        "    event_name=ignite.engine.Events.EPOCH_COMPLETED,\n",
        "    handler=checkpoint_handler,\n",
        "    to_save={\"net\": net, \"opt\": opt},\n",
        ")\n",
        "\n",
        "# StatsHandler prints loss at every iteration\n",
        "# user can also customize print functions and can use output_transform to convert\n",
        "# engine.state.output if it's not a loss value\n",
        "train_stats_handler = StatsHandler(name=\"trainer\", output_transform=lambda x: x)\n",
        "train_stats_handler.attach(trainer)\n",
        "\n",
        "# TensorBoardStatsHandler plots loss at every iteration\n",
        "train_tensorboard_stats_handler = TensorBoardStatsHandler(log_dir=log_dir, output_transform=lambda x: x)\n",
        "train_tensorboard_stats_handler.attach(trainer)\n",
        "\n",
        "# MLFlowHandler plots loss at every iteration on MLFlow web UI\n",
        "mlflow_dir = os.path.join(log_dir, \"mlruns\")\n",
        "train_mlflow_handler = MLFlowHandler(tracking_uri=Path(mlflow_dir).as_uri(), output_transform=lambda x: x)\n",
        "train_mlflow_handler.attach(trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nch3uaPSN-aF"
      },
      "source": [
        "## Add Validation every N epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUxiBmHqN-aF"
      },
      "outputs": [],
      "source": [
        "# optional section for model validation during training\n",
        "validation_every_n_epochs = 1\n",
        "# Set parameters for validation\n",
        "metric_name = \"Mean_Dice\"\n",
        "# add evaluation metric to the evaluator engine\n",
        "val_metrics = {metric_name: MeanDice()}\n",
        "post_pred = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
        "post_label = Compose([AsDiscrete(threshold=0.5)])\n",
        "# Ignite evaluator expects batch=(img, seg) and\n",
        "# returns output=(y_pred, y) at every iteration,\n",
        "# user can add output_transform to return other values\n",
        "evaluator = ignite.engine.create_supervised_evaluator(\n",
        "    net,\n",
        "    val_metrics,\n",
        "    device,\n",
        "    True,\n",
        "    output_transform=lambda x, y, y_pred: (\n",
        "        [post_pred(i) for i in decollate_batch(y_pred)],\n",
        "        [post_label(i) for i in decollate_batch(y)],\n",
        "    ),\n",
        ")\n",
        "\n",
        "# create a validation data loader\n",
        "val_imtrans = Compose(\n",
        "    [\n",
        "        LoadImage(image_only=True),\n",
        "        ScaleIntensity(),\n",
        "        EnsureChannelFirst(),\n",
        "        Resize((96, 96, 96)),\n",
        "    ]\n",
        ")\n",
        "val_segtrans = Compose(\n",
        "    [\n",
        "        LoadImage(image_only=True),\n",
        "        EnsureChannelFirst(),\n",
        "        Resize((96, 96, 96)),\n",
        "    ]\n",
        ")\n",
        "val_ds = ArrayDataset(images[21:], val_imtrans, segs[21:], val_segtrans)\n",
        "val_loader = DataLoader(val_ds, batch_size=5, num_workers=8, pin_memory=torch.cuda.is_available())\n",
        "\n",
        "\n",
        "@trainer.on(ignite.engine.Events.EPOCH_COMPLETED(every=validation_every_n_epochs))\n",
        "def run_validation(engine):\n",
        "    evaluator.run(val_loader)\n",
        "\n",
        "\n",
        "# Add stats event handler to print validation stats via evaluator\n",
        "val_stats_handler = StatsHandler(\n",
        "    name=\"evaluator\",\n",
        "    # no need to print loss value, so disable per iteration output\n",
        "    output_transform=lambda x: None,\n",
        "    # fetch global epoch number from trainer\n",
        "    global_epoch_transform=lambda x: trainer.state.epoch,\n",
        ")\n",
        "val_stats_handler.attach(evaluator)\n",
        "\n",
        "# add handler to record metrics to TensorBoard at every validation epoch\n",
        "val_tensorboard_stats_handler = TensorBoardStatsHandler(\n",
        "    log_dir=log_dir,\n",
        "    # no need to plot loss value, so disable per iteration output\n",
        "    output_transform=lambda x: None,\n",
        "    # fetch global epoch number from trainer\n",
        "    global_epoch_transform=lambda x: trainer.state.epoch,\n",
        ")\n",
        "val_tensorboard_stats_handler.attach(evaluator)\n",
        "\n",
        "# add handler to record metrics to MLFlow at every validation epoch\n",
        "val_mlflow_handler = MLFlowHandler(\n",
        "    tracking_uri=Path(mlflow_dir).as_uri(),\n",
        "    # no need to plot loss value, so disable per iteration output\n",
        "    output_transform=lambda x: None,\n",
        "    # fetch global epoch number from trainer\n",
        "    global_epoch_transform=lambda x: trainer.state.epoch,\n",
        ")\n",
        "val_mlflow_handler.attach(evaluator)\n",
        "\n",
        "# add handler to draw the first image and the corresponding\n",
        "# label and model output in the last batch\n",
        "# here we draw the 3D output as GIF format along Depth\n",
        "# axis, at every validation epoch\n",
        "val_tensorboard_image_handler = TensorBoardImageHandler(\n",
        "    log_dir=log_dir,\n",
        "    batch_transform=lambda batch: (batch[0], batch[1]),\n",
        "    output_transform=lambda output: output[0],\n",
        "    global_iter_transform=lambda x: trainer.state.epoch,\n",
        ")\n",
        "evaluator.add_event_handler(\n",
        "    event_name=ignite.engine.Events.EPOCH_COMPLETED,\n",
        "    handler=val_tensorboard_image_handler,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHSR4uVLN-aG"
      },
      "source": [
        "## Run training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "lus_CxEON-aG"
      },
      "outputs": [],
      "source": [
        "# create a training data loader\n",
        "train_ds = ArrayDataset(images[:20], imtrans, segs[:20], segtrans)\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=5,\n",
        "    shuffle=True,\n",
        "    num_workers=8,\n",
        "    pin_memory=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "max_epochs = 10\n",
        "state = trainer.run(train_loader, max_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5azvrRq9N-aG"
      },
      "source": [
        "## Visualizing Tensorboard logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5ObC6XpN-aG"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=$log_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzo0h35xN-aG"
      },
      "source": [
        "Expected training curve on TensorBoard:\n",
        "![image-2.png](attachment:image-2.png) ![image-4.png](attachment:image-4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syseumJdN-aG"
      },
      "source": [
        "## Visualizing training status in MLFlow\n",
        "\n",
        "As `mlflow` is not IPython component, please switch to the `log_dir` and execute command `mlflow ui` to launch MLFlow UI.\n",
        "\n",
        "Expected training curve on MLFlow UI:\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f8df-kBN-aG"
      },
      "source": [
        "## Cleanup data directory\n",
        "\n",
        "Remove directory if a temporary was used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "nKVA6DxRN-aH"
      },
      "outputs": [],
      "source": [
        "if directory is None:\n",
        "    shutil.rmtree(root_dir)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}