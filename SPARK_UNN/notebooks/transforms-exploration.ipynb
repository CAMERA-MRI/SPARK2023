{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentations Check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing:\n",
    "Here we will check what effects torchio transformations have on each volume\n",
    "1. Crop or Pad\n",
    "2. Mask - normalisation using label as a mask\n",
    "3. One Hot Encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data using the data_prep code\n",
    "**NB: DO NOT RUN THE DATA PREPROC PART YET**\n",
    "\n",
    "To ensure we are just working with a few functions at a time, py script is copied in below without preproc. We will run each example on several SSA and GLI datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some functions from scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import nibabel as nib\n",
    "    import os\n",
    "    import random\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    import torch\n",
    "    import json\n",
    "    from glob import glob\n",
    "    import time\n",
    "    import numpy as np\n",
    "    from matplotlib import rcParams \n",
    "    import torchio as tio\n",
    "except ModuleNotFoundError as e:\n",
    "    package = str(e).split(\"'\")[0]\n",
    "    subprocess.run(['pip', 'install', package])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data files\n",
    "\n",
    "# CHANGE data_dir path as per your local set up\n",
    "pthAlex = '/Users/alexandrasmith/Desktop/Workspace/Projects/UNN_BraTS23/data/ASNR-MICCAI-BraTS2023-SSA-Challenge-TrainingData/'\n",
    "pthAly = 'C:\\\\Users\\\\XXXX\\\\Documents\\\\SPARK\\\\BraTS2023\\\\Data\\\\Samples\\\\'\n",
    "\n",
    "data_dir = pthAly\n",
    "print(data_dir)\n",
    "specific_string = 'BraTS-'\n",
    "# folders = os.listdir(data_dir)\n",
    "subject_dirs = sorted([os.path.join(data_dir, subject_dir) for subject_dir in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, subject_dir)) and subject_dir.startswith(specific_string)])\n",
    "\n",
    "print(\"Total folders: \", len(subject_dirs), \"\\n Subjects:\\n\",  \"\\n\".join(subject_dirs))\n",
    "\n",
    "# Iterate through the subject folders\n",
    "subjects = []\n",
    "for subject_dir in subject_dirs:\n",
    "    subject_id = os.path.basename(subject_dir)\n",
    "    print(subject_dir)\n",
    "    # Create a list to hold the subject's images and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Load each scan modality and segmentation\n",
    "    for modality in ['t1n', 't1c', 't2w', 't2f']:\n",
    "        image_path = os.path.join(subject_dir, f'{subject_id}-{modality}.nii.gz')\n",
    "        image = tio.ScalarImage(image_path)\n",
    "        images.append(image)\n",
    "\n",
    "    label_path = os.path.join(subject_dir, f'{subject_id}-seg.nii.gz')\n",
    "    label = tio.LabelMap(label_path)\n",
    "    labels.append(label)\n",
    "\n",
    "    # Create the subject using the images and labels\n",
    "    subject = tio.Subject(\n",
    "        t1n=images[0],\n",
    "        t1c=images[1],\n",
    "        t2w=images[2],\n",
    "        t2f=images[3],\n",
    "        seg=labels[0],\n",
    "        name=subject_id\n",
    "    )\n",
    "    subjects.append(subject)\n",
    "# Create the dataset with the subject\n",
    "dataset = tio.SubjectsDataset(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select one subject to Explore\n",
    "specific_string = 'BraTS-'\n",
    "# folders = os.listdir(data_dir)\n",
    "folders = [folder for folder in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, folder)) and folder.startswith(specific_string)]\n",
    "\n",
    "print(\"Total folders: \", len(folders), \"\\n Subjects: \",  folders)\n",
    "#randomly select a subject\n",
    "img_folder = folders[random.randrange(0, len(folders))]\n",
    "print(f\"Working with subject: {img_folder}\")\n",
    "\n",
    "## Set up files\n",
    "# Load image volumes\n",
    "img_volumes = [nib.load(os.path.join(data_dir + img_folder, img_folder + f\"-{m}.nii.gz\")) for m in [\"t1c\", \"t1n\", \"t2f\", \"t2w\"]]\n",
    "\n",
    "# Load segmentation volume\n",
    "seg_volume = nib.load(os.path.join(data_dir + img_folder, img_folder + \"-seg.nii.gz\"))\n",
    "\n",
    "subjects = [subj for subj in folders] \n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# Define the original array\n",
    "original_array = np.random.random((240, 240, 155))\n",
    "\n",
    "# Define the scaling factor\n",
    "scale_factor = 0.8\n",
    "\n",
    "# Calculate the new dimensions\n",
    "new_shape = tuple(int(dim * scale_factor) for dim in original_array.shape)\n",
    "\n",
    "# Scale down the array\n",
    "scaled_array = zoom(original_array, scale_factor)\n",
    "\n",
    "# Verify the new shape\n",
    "print(\"Original shape:\", original_array.shape)\n",
    "print(\"Scaled shape:\", scaled_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_ras = tio.ToCanonical()\n",
    "crop_pad_Zlbl = tio.CropOrPad((192, 224, 160), mask_name=\"seg\")\n",
    "crop_padZ = tio.CropOrPad((192, 224, 160))\n",
    "crop_padSc = tio.CropOrPad((192, 192, 124))\n",
    "crop_pad_lbl = tio.CropOrPad(mask_name=\"seg\")\n",
    "# Define the list of transformations to apply\n",
    "flipR = tio.RandomFlip(axes=(0, 1, 2), p=0.8)\n",
    "resampleR = tio.Resample((1.2, 1.2, 6))\n",
    "anisoR = tio.RandomAnisotropy(axes=(0, 1, 2), downsampling=(1, 6))\n",
    "blurR = tio.RandomBlur(std=(0.5, 1.5))\n",
    "noiseR = tio.RandomNoise(mean=0, std=(0, 0.33))\n",
    "motionR = tio.RandomMotion(num_transforms=3, image_interpolation='nearest')\n",
    "biasfR = tio.RandomBiasField(coefficients=1)\n",
    "ghostR = tio.RandomGhosting(intensity=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs_trans = []\n",
    "for subject in dataset.dry_iter():\n",
    "    print(subject.name)\n",
    "    if subject.name == 'BraTS-GLI-00002-000':\n",
    "        subjs_trans.append(subject)\n",
    "    elif subject.name == 'BraTS-SSA-00081-000':\n",
    "        subjs_trans.append(subject)\n",
    "    else:\n",
    "        continue\n",
    "print(subjs_trans)\n",
    "subjs_trans_dataset = tio.SubjectsDataset(subjs_trans)\n",
    "for subject in subjs_trans_dataset.dry_iter():\n",
    "    print(subject.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in subjs_trans_dataset:\n",
    "    print(s.name)\n",
    "    ras = to_ras(s)\n",
    "    ras.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops = [crop_padSc, crop_padZ, crop_pad_Zlbl, crop_pad_lbl]\n",
    "for crop in crops:\n",
    "    for s in subjs_trans_dataset:\n",
    "        print(s.name)\n",
    "        print(f\"cropping subject using {crop}\")\n",
    "        cropped = crop(s)\n",
    "        cropped.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = [flipR, blurR, noiseR, motionR, biasfR, ghostR, resampleR, anisoR]\n",
    "for aug in augs:\n",
    "    for s in subjs_trans_dataset:\n",
    "        print(f\"Applying {aug} to subject {s.name}\")\n",
    "        ras = to_ras(s)\n",
    "        augment = aug(ras)\n",
    "        augment.plot()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# defined transformations\n",
    "augs = [flipR, blurR, noiseR, motionR, biasfR, ghostR, resampleR, anisoR]\n",
    "for aug in augs:\n",
    "    for s in subjs_trans_dataset:\n",
    "        print(f\"Applying {aug} to subject {s.name}\")\n",
    "        ras = to_ras(s)\n",
    "        augment = aug(ras)\n",
    "        plt.figure(figsize=[10, 10])  # Adjust the width and height as per your preference\n",
    "        augment.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchio as tio\n",
    "\n",
    "data_path = 'C:\\\\Users\\\\XXXX\\\\Documents\\\\SPARK\\\\BraTS2023\\\\Data\\\\Samples\\\\BraTS-GLI-00002-000\\\\'\n",
    "image_path = 'C:\\\\Users\\\\XXXX\\\\Documents\\\\SPARK\\\\BraTS2023\\\\Data\\\\Samples\\\\BraTS-GLI-00002-000\\\\BraTS-GLI-00002-000-stk.nii.gz'\n",
    "label_path = 'C:\\\\Users\\\\XXXX\\\\Documents\\\\SPARK\\\\BraTS2023\\\\Data\\\\Samples\\\\BraTS-GLI-00002-000\\\\BraTS-GLI-00002-000-lbl.nii.gz'\n",
    "\n",
    "# Define the number of classes (including background)\n",
    "num_classes = 4\n",
    "\n",
    "# Create the TorchIO subject\n",
    "subject = tio.Subject(\n",
    "    image=tio.ScalarImage(os.path.join(data_path, image_path)),\n",
    "    label=tio.LabelMap(os.path.join(data_path, label_path))\n",
    ")\n",
    "\n",
    "ohe = tio.OneHot(num_classes)\n",
    "ohe_sub = ohe(subject)\n",
    "transformed_image = ohe_sub[\"image\"].data\n",
    "transformed_label = ohe_sub[\"label\"].data\n",
    "# Apply one-hot encoding to the image\n",
    "one_hot_image = tio.OneHot(num_classes)(subject.image)\n",
    "\n",
    "# Apply one-hot encoding to the label\n",
    "one_hot_label = tio.OneHot(num_classes)(subject.label)\n",
    "\n",
    "# Access the one-hot encoded tensors\n",
    "one_hot_image_tensor = one_hot_image.data\n",
    "one_hot_label_tensor = one_hot_label.data\n",
    "\n",
    "\n",
    "print(transformed_image.shape==one_hot_image_tensor.shape)\n",
    "print(transformed_label.shape==one_hot_label_tensor.shape)\n",
    "# # Print the shape of the one-hot encoded tensors\n",
    "# print(one_hot_image_tensor.shape)\n",
    "# print(one_hot_label_tensor.shape)\n",
    "# # Find the minimum and maximum values\n",
    "# min_value = torch.min(one_hot_label_tensor)\n",
    "# max_value = torch.max(one_hot_label_tensor)\n",
    "\n",
    "# # Print the minimum and maximum values\n",
    "# print(\"Minimum value:\", min_value.item())\n",
    "# print(\"Maximum value:\", max_value.item())\n",
    "\n",
    "# print(one_hot_label_tensor[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL VISUALISATION -- Some parts are not fully functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchio as tio\n",
    "\n",
    "data_dir = 'C:\\\\Users\\\\XXXX\\\\Documents\\\\SPARK\\\\BraTS2023\\\\Data\\\\BraTS2023-SSA-TrainingData\\\\'\n",
    "output_dir = 'C:\\\\Users\\\\XXXX\\\\Documents\\\\SPARK\\\\BraTS2023\\\\Data\\\\BraTS2023-SSA-TrainingData\\\\output'\n",
    "\n",
    "modalities = ['t1n', 't2w', 't1c', 't2f', 'seg']\n",
    "views = ['axial', 'sagittal', 'coronal']\n",
    "\n",
    "transformations = [\n",
    "    tio.ToCanonical(),\n",
    "    tio.CropOrPad((192, 224, 160), mask_name=\"label\"),\n",
    "    tio.CropOrPad((192, 224, 160)),\n",
    "    tio.CropOrPad((192, 192, 124)),\n",
    "    tio.CropOrPad(mask_name=\"label\"),\n",
    "    tio.RandomFlip(axes=(0, 1, 2), p=0.3),\n",
    "    tio.Resample((1.2, 1.2, 6)),\n",
    "    tio.RandomAnisotropy(axes=(0, 1, 2), downsampling=(1, 6)),\n",
    "    tio.RandomBlur(std=(0.5, 1.5)),\n",
    "    tio.RandomNoise(mean=0, std=(0, 0.33)),\n",
    "    tio.RandomMotion(num_transforms=3, image_interpolation='nearest'),\n",
    "    tio.RandomBiasField(coefficients=1),\n",
    "    tio.RandomGhosting(intensity=1.5)\n",
    "]\n",
    "\n",
    "specific_string = 'BraTS-'\n",
    "folders = [folder for folder in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, folder)) and folder.startswith(specific_string)]\n",
    "subjects = [subj for subj in folders]\n",
    "\n",
    "subjects_tio = []\n",
    "for subject in subjects:\n",
    "    subject_dir = os.path.join(data_dir, subject)\n",
    "    subject_images = {}\n",
    "    \n",
    "    for modality in modalities:\n",
    "        file_pth = os.path.join(subject_dir, f'{subject}-{modality}.nii.gz')\n",
    "        \n",
    "        if modality == 'seg' and file_pth in seg_p:\n",
    "            subject_images[\"label\"] = tio.LabelMap(file_pth)\n",
    "        else:\n",
    "            subject_images[modality] = tio.ScalarImage(file_pth)\n",
    "    \n",
    "    subject_tio = tio.Subject(**subject_images)\n",
    "    subjects_tio.append(subject_tio)\n",
    "\n",
    "print(subjects_tio)\n",
    "\n",
    "for modality in modalities:\n",
    "    for subject in subjects_tio:\n",
    "        fig, axes = plt.subplots(len(views), len(transformations), figsize=(20, 20))\n",
    "        fig.suptitle(f'{subject} - {modality.capitalize()} Transforms')\n",
    "\n",
    "        for i, view in enumerate(views):\n",
    "            for j, transformation in enumerate(transformations):\n",
    "                transformed_image = transformation(subject)\n",
    "\n",
    "                if view == 'axial':\n",
    "                    img = transformed_image.plot(axial=True)\n",
    "                elif view == 'sagittal':\n",
    "                    img = transformed_image.plot(sagittal=True)\n",
    "                elif view == 'coronal':\n",
    "                    img = transformed_image.plot(coronal=True)\n",
    "\n",
    "                axes[i, j].imshow(img, cmap='gray')\n",
    "                axes[i, j].axis('off')\n",
    "\n",
    "                # Save figure as .png file\n",
    "                filename = f'{modality}_{view}_{j+1}.png'\n",
    "                plt.savefig(os.path.join(output_dir, filename))\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchio as tio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the main data directory path\n",
    "data_dir = '/scratch/XXXX/BraTS2023_OriginalData/TrainingData_release/ASNR-MICCAI-BraTS2023-SSA-Challenge-TrainingData_V2'\n",
    "output_dir = '/home/XXXX/GitRepo_Brats23/UNN_BraTS23/reports'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the list of transformations to apply\n",
    "transformations = [\n",
    "    tio.ToCanonical(),\n",
    "    tio.CropOrPad((192, 224, 160), mask_name=\"seg\"),\n",
    "    tio.CropOrPad((192, 224, 160)),\n",
    "    tio.CropOrPad((192, 192, 124)),\n",
    "    tio.CropOrPad(mask_name=\"seg\"),\n",
    "    tio.RandomFlip(axes=(0, 1, 2), p=0.3),\n",
    "    tio.Resample((1.2, 1.2, 6)),\n",
    "    tio.RandomAnisotropy(axes=(0, 1, 2), downsampling=(1, 6)),\n",
    "    tio.RandomBlur(std=(0.5, 1.5)),\n",
    "    tio.RandomNoise(mean=0, std=(0, 0.33)),\n",
    "    tio.RandomMotion(num_transforms=3, image_interpolation='nearest'),\n",
    "    tio.RandomBiasField(coefficients=1),\n",
    "    tio.RandomGhosting(intensity=1.5)\n",
    "]\n",
    "\n",
    "# Iterate through the subject folders\n",
    "subject_dirs = sorted([os.path.join(data_dir, subject_dir) for subject_dir in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, subject_dir))])\n",
    "for subject_dir in subject_dirs:\n",
    "    subject_id = os.path.basename(subject_dir)\n",
    "    print(subject_dir)\n",
    "    # Create a list to hold the subject's images and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Load each scan modality and segmentation\n",
    "    for modality in ['t1n', 't1c', 't2w', 't2f']:\n",
    "        image_path = os.path.join(subject_dir, f'{subject_id}-{modality}.nii.gz')\n",
    "        image = tio.ScalarImage(image_path)\n",
    "        images.append(image)\n",
    "\n",
    "    label_path = os.path.join(subject_dir, f'{subject_id}-seg.nii.gz')\n",
    "    label = tio.LabelMap(label_path)\n",
    "    labels.append(label)\n",
    "\n",
    "    # Create the subject using the images and labels\n",
    "    subject = tio.Subject(\n",
    "        t1n=images[0],\n",
    "        t1c=images[1],\n",
    "        t2w=images[2],\n",
    "        t2f=images[3],\n",
    "        seg=labels[0]\n",
    "    )\n",
    "\n",
    "    # Create the dataset with the subject\n",
    "    dataset = tio.SubjectsDataset([subject])\n",
    "\n",
    "    # Apply transformations and save the resulting figures\n",
    "    transformed_subjects = []\n",
    "    for current_transformation in transformations:\n",
    "        for current_subject in dataset:\n",
    "            transformed_subject = current_transformation(current_subject)\n",
    "            transformed_subjects.append(transformed_subject)\n",
    "\n",
    "transformed_dataset = tio.SubjectsDataset(transformed_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure for all views\n",
    "fig, axes = plt.subplots(len(subject_dirs), 4, figsize=(12, 3 * len(subject_dirs)))\n",
    "\n",
    "# Iterate through the transformed subjects and plot the images\n",
    "for subject_index, transformed_subject in enumerate(transformed_dataset):\n",
    "    # Get the transformed images and labels\n",
    "    transformed_images = [transformed_subject['t1n'], transformed_subject['t1c'], transformed_subject['t2w'], transformed_subject['t2f']]\n",
    "    transformed_label = transformed_subject['seg']\n",
    "\n",
    "    # Iterate through the views and plot the images\n",
    "    for j, view in enumerate(['axial', 'coronal', 'sagittal']):\n",
    "        ax = axes[subject_index, j]\n",
    "        ax.imshow(transformed_images[j].data.squeeze().numpy()[:,:,view])\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'{modality.upper()} {view}')\n",
    "\n",
    "    # Plot the segmentation label for the current subject\n",
    "    ax = axes[subject_index, 3]\n",
    "    ax.imshow(transformed_label.data.squeeze().numpy()[:,:,view])\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Segmentation')\n",
    "\n",
    "# Save the figure as an EPS file\n",
    "output_filename = f'all_subjects_{view}_{transformation.name}.eps'\n",
    "output_path = os.path.join(output_dir, output_filename)\n",
    "plt.savefig(output_path, format='eps')\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure for all views\n",
    "fig, axes = plt.subplots(len(subject_dirs), 4, figsize=(12, 3 * len(subject_dirs)))\n",
    "\n",
    "# Iterate through the transformed subjects and plot the images\n",
    "for subject_index, transformed_subject in enumerate(transformed_dataset):\n",
    "    # Get the transformed images and labels\n",
    "    transformed_images = [transformed_subject['t1n'], transformed_subject['t1c'], transformed_subject['t2w'], transformed_subject['t2f']]\n",
    "    transformed_label = transformed_subject['seg']\n",
    "\n",
    "# Iterate through the views and plot the images\n",
    "    for j, view in enumerate(['axial', 'coronal', 'sagittal']):\n",
    "        ax = axes[subject_index, j]\n",
    "        # Convert view to an integer if necessary\n",
    "        if isinstance(view, str):\n",
    "            view = {'axial': 0, 'coronal': 1, 'sagittal': 2}[view]\n",
    "        ax.imshow(transformed_images[j].data.squeeze().numpy()[:,:,view])\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'{modality.upper()} {view}')\n",
    "\n",
    "        # Plot the segmentation label for the current subject\n",
    "        ax = axes[subject_index, 3]\n",
    "        ax.imshow(transformed_label.data.squeeze().numpy()[:,:,view])\n",
    "        ax.axis('off')\n",
    "        ax.set_title('Segmentation')\n",
    "\n",
    "# Save the figure as an EPS file\n",
    "output_filename = f'all_subjects_{view}_{transformation.name}.eps'\n",
    "output_path = os.path.join(output_dir, output_filename)\n",
    "plt.savefig(output_path, format='eps')\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import nibabel as nib\n",
    "    import os\n",
    "    import random\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    import torch\n",
    "    import json\n",
    "    from glob import glob\n",
    "    import time\n",
    "    import numpy as np\n",
    "    from matplotlib import rcParams \n",
    "    import torchio as tio\n",
    "except ModuleNotFoundError as e:\n",
    "    package = str(e).split(\"'\")[0]\n",
    "    subprocess.run(['pip', 'install', package])\n",
    "\n",
    "\n",
    "# Set the main data directory path\n",
    "data_dir = '/scratch/XXXX/BraTS2023_OriginalData/TrainingData_release/ASNR-MICCAI-BraTS2023-SSA-Challenge-TrainingData_V2'\n",
    "output_dir = '/home/XXXX/GitRepo_Brats23/UNN_BraTS23/reports'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the list of transformations to apply\n",
    "transformations = [\n",
    "    tio.ToCanonical(),\n",
    "    tio.CropOrPad((192, 224, 160), mask_name=\"seg\"),\n",
    "    tio.CropOrPad((192, 224, 160)),\n",
    "    tio.CropOrPad((192, 192, 124)),\n",
    "    tio.CropOrPad(mask_name=\"seg\"),\n",
    "    tio.RandomFlip(axes=(0, 1, 2), p=0.3),\n",
    "    tio.Resample((1.2, 1.2, 6)),\n",
    "    tio.RandomAnisotropy(axes=(0, 1, 2), downsampling=(1, 6)),\n",
    "    tio.RandomBlur(std=(0.5, 1.5)),\n",
    "    tio.RandomNoise(mean=0, std=(0, 0.33)),\n",
    "    tio.RandomMotion(num_transforms=3, image_interpolation='nearest'),\n",
    "    tio.RandomBiasField(coefficients=1),\n",
    "    tio.RandomGhosting(intensity=1.5)\n",
    "]\n",
    "\n",
    "pthAly = 'C:\\\\Users\\\\XXXX\\\\Documents\\\\SPARK\\\\BraTS2023\\\\Data\\\\Samples\\\\'\n",
    "\n",
    "data_dir = pthAly\n",
    "print(data_dir)\n",
    "specific_string = 'BraTS-'\n",
    "# folders = os.listdir(data_dir)\n",
    "subject_dirs = sorted([os.path.join(data_dir, subject_dir) for subject_dir in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, subject_dir)) and subject_dir.startswith(specific_string)])\n",
    "\n",
    "print(\"Total folders: \", len(subject_dirs), \"\\n Subjects:\\n\",  \"\\n\".join(subject_dirs))\n",
    "\n",
    "# Iterate through the subject folders\n",
    "subjects = []\n",
    "for subject_dir in subject_dirs:\n",
    "    subject_id = os.path.basename(subject_dir)\n",
    "    print(subject_dir)\n",
    "    # Create a list to hold the subject's images and labels\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Load each scan modality and segmentation\n",
    "    for modality in ['t1n', 't1c', 't2w', 't2f']:\n",
    "        image_path = os.path.join(subject_dir, f'{subject_id}-{modality}.nii.gz')\n",
    "        image = tio.ScalarImage(image_path)\n",
    "        images.append(image)\n",
    "\n",
    "    label_path = os.path.join(subject_dir, f'{subject_id}-seg.nii.gz')\n",
    "    label = tio.LabelMap(label_path)\n",
    "    labels.append(label)\n",
    "\n",
    "    # Create the subject using the images and labels\n",
    "    subject = tio.Subject(\n",
    "        t1n=images[0],\n",
    "        t1c=images[1],\n",
    "        t2w=images[2],\n",
    "        t2f=images[3],\n",
    "        seg=labels[0],\n",
    "        name=subject_id\n",
    "    )\n",
    "    subjects.append(subject)\n",
    "# Create the dataset with the subject\n",
    "dataset = tio.SubjectsDataset(subjects)\n",
    "\n",
    "n_plots = len(dataset)\n",
    "n_cols = 6\n",
    "n_rows = (n_plots + n_cols - 1) // n_cols  # Calculate the number of rows needed\n",
    "view_mapping = {\n",
    "    'axial': 2,\n",
    "    'coronal': 1,\n",
    "    'sagittal': 0\n",
    "}\n",
    "\n",
    "\n",
    "for modality in dataset[0].keys():\n",
    "    # Iterate over each view\n",
    "    for v, n in view_mapping.items():\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 20))\n",
    "        fig.suptitle(f'{modality.capitalize()} - {v.capitalize()} Views')\n",
    "\n",
    "        # Iterate over each subject\n",
    "        for idx, subject in enumerate(dataset):\n",
    "            # Get the volume tensor\n",
    "            data = subject[modality][tio.DATA]\n",
    "            half_shape = torch.Tensor(subject.spatial_shape) // 2\n",
    "            i, j, k = half_shape.long()\n",
    "            slices = data[0, i], data[0, :, j], data[0, ..., k]\n",
    "            sag, cor, axi = slices\n",
    "           \n",
    "            slice_tensor = slices[view_mapping[v]]\n",
    "            \n",
    "            # Calculate row and column indices for each subplot\n",
    "            row_index = i // n_cols\n",
    "            col_index = i % n_cols\n",
    "\n",
    "            # Plot the slice\n",
    "            ax = axes[row_index, col_index]\n",
    "            ax.imshow(slice_tensor.numpy(), cmap='gray')\n",
    "            ax[-1].set_title(f'{img_folder}', loc='right')\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
