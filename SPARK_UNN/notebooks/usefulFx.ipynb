{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some functions from nnUNET\n",
    "def load_nifty(directory, example_id, suffix):\n",
    "    \"\"\"\n",
    "    Loads a nifti file from the given (directory)\n",
    "    with the given example_id and suffix\n",
    "    \"\"\"\n",
    "    return nibabel.load(os.path.join(directory, example_id + \"_\" + suffix + \".nii.gz\"))\n",
    "\n",
    "def load_channels(d, example_id):\n",
    "    \"\"\"\n",
    "    Loads four nifti files from the given directory (d)\n",
    "    with the given (example_id )\n",
    "    and the suffixes \"flair\", \"t1\", \"t1ce\", \"t2\"\n",
    "    \"\"\"\n",
    "    return [load_nifty(d, example_id, suffix) for suffix in [\"t1c\", \"t1n\", \"t2f\", \"t2w\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some fx based on data exploration\n",
    "def load_modalities(modalities, data_dir):\n",
    "    # Create paths for each modality \n",
    "    img_modalitypth = [(os.path.join(data_dir + img_folder, img_folder + f\"-{m}.nii.gz\")) for m in modalities]\n",
    "    ## double check for files loaded\n",
    "    for i in range(len(img_modalitypth)) : print(os.path.basename(img_modalitypth[i]))  #double check files loaded\n",
    "    \n",
    "    # load modalities into a list, generate headers\n",
    "    img_modality = []\n",
    "    hdrs = {}\n",
    "    for idx, mname in enumerate(modalities):\n",
    "        globals()[f'{mname}_img'] = nib.load(img_modalitypth[idx])\n",
    "        img_modality.append(globals()[f'{mname}_img'])\n",
    "        hdrs[f'{mname}_img'] = img_modality[idx].header\n",
    "        print(f\"Dimensions for modality {mname} is {img_modality[idx].shape}, with isotropic resolution of {hdrs[f'{mname}_img'].get_zooms()} \")\n",
    "    return img_modality, hdrs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GANDLF PREPROC\n",
    "Intensity harmonization: GaNDLF provides multiple normalization and rescaling options to ensure intensity-level harmonization of the entire cohort. Some examples include:\n",
    "- normalize: simple Z-score normalization\n",
    "- normalize_positive: this performs z-score normalization only on pixels > 0\n",
    "- normalize_nonZero: this performs z-score normalization only on pixels != 0\n",
    "- normalize_nonZero_masked: this performs z-score normalization only on the region defined by the ground truth annotation\n",
    "- rescale: simple min-max rescaling, sub-parameters include in_min_max, out_min_max, percentiles; this option is useful to discard outliers in the intensity distribution\n",
    "- Template-based normalization: These options take a target image as input (defined by the target sub-parameter) and perform different matching strategies to match input image(s) to this target.\n",
    "- histogram_matching: this performs histogram matching as defined by this paper.\n",
    "    - If the target image is absent, this will perform global histogram equalization.\n",
    "    - If target is adaptive, this will perform adaptive histogram equalization.\n",
    "- Resolution harmonization: GaNDLF provides multiple resampling options to ensure resolution-level harmonization of the entire cohort. Some examples include:\n",
    "- resample: resamples the image to the specified by the resolution sub-parameter\n",
    "- resample_min: resamples the image to the maximum spacing defined by the resolution sub-parameter; this is useful in cohorts that have varying resolutions, but the user wants to resample to the minimum resolution for consistency\n",
    "- resize_image: NOT RECOMMENDED; resizes the image to the specified size\n",
    "- resize_patch: NOT RECOMMENDED; resizes the extracted patch to the specified size"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
